{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gender Identification using BI LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nog_0J_Uy-YA",
        "outputId": "a3dea920-7602-4989-cc4b-b193f09be3b9"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- AUTHOR_DETAILS -------------\n",
        "    |\n",
        "    |   __Project Title__   = Developing a Gender Prediction System using Bidirectional LSTM-based Deep Neural Networks \n",
        "    |   \n",
        "    |   __author__          = Ms. Hira Arshad\n",
        "    |\n",
        "    |   __copyright__       = Copyright (C) 2020 Ms. Hira Arshad\n",
        "    |\n",
        "    |   __license__         = Public Domain\n",
        "    |\n",
        "    |   __version__         = 1.0\n",
        "    *------------------------------------------------------------\n",
        "'''\n",
        "print()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pv-DNnLhUhJ"
      },
      "source": [
        "**Note:** Before running the code file set **\"drive_path\"** variable value depending upon your folder location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_N4-F2MyNkC",
        "outputId": "ab4cfa40-b50c-4fba-8385-c41057f8b1b6"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- PROJECT_PURPOSE -------------\n",
        "    | - The main purpose of this program is to demonstrate how Bidirectioanl LSTM-based Deep Neural Network can be used for the development \n",
        "    |   and evaluation of Gender Prediction from Text (i.e. a Binary Classification Problem). For this purpose, Insha Allah, I will execute the Machine Learning Cycle\n",
        "    *------------------------------------------------------------\n",
        "'''\n",
        "print()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfU-DkA_xdvM"
      },
      "source": [
        "# **Machine Learning Cycle**\n",
        "## **Four phases of a Machine Learning Cycle are**\n",
        "### **Training Phase**\n",
        "  * **Build the Model using Training Data**\n",
        "\n",
        "### **Testing Phase**\n",
        "  * **Evaluate the performance of Model using Testing Data**\n",
        "\n",
        "### **Application Phase**\n",
        "  * **Deploy the Model in Real-world , to make prediction on Real-time unseen Data**\n",
        "  \n",
        "### **Feedback Phase**\n",
        "  * **Take Feedback form the Users and Domain Experts to improve the Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9gFROU5vI8d"
      },
      "source": [
        "# **Steps – Executing Machine Learning Cycle Using Separate Files**\n",
        "* **Step 1: Import Libraries**\n",
        "* **Step 2: Load Training Data, Testing Data and Validation Data**\n",
        "* **Step 3: Understand and Pre-process Training Data, Testing Data and  Validation Data**\n",
        "* **Step 4: Represent Training Data, Testing Data and Validation Data in Machine Understandable Format**\n",
        "* **Step 5: Execute the Training Phase**\n",
        "* **Step 6: Execute the Testing Phase**\n",
        "* **Step 7: Execute the Application Phase**\n",
        "* **Step 8: Execute the Feedback Phase**\n",
        "* **Step 9: Improve Model Based on Feedback**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEc01RbkwsGw"
      },
      "source": [
        "# **Step 1: Import Libraries**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gReWlANUTmTA"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- IMPORT_LIBRARIES -------------\n",
        "'''\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import spacy\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext import data\n",
        "import torch.optim as optim\n",
        "from torchtext import vocab\n",
        "import torch.nn.functional as F\n",
        "from torchtext.data import Field\n",
        "from torch.autograd import Variable\n",
        "from torchtext.vocab import Vectors\n",
        "from torchtext.data import TabularDataset\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQz1f44_wkgA"
      },
      "source": [
        "Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhoYmHeBTopv",
        "outputId": "8c6dbe4c-a4e6-4f95-b1d2-61fbc3a225ca"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- MOUNT_GOOGLE_DRIVE -------------\n",
        "      - To connect your colab notebook with google drive\n",
        "'''    \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKfd525Swy2g"
      },
      "source": [
        "# **Step 2: Load Training Data, Testing Data and Validation Data**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkqrZtTk-b3w"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- LOAD_DATASET -------------\n",
        "    | Function  : load_dataset()\n",
        "    | Purpose   : Reads dataset(s) in CSV file format \n",
        "    | Arguments : \n",
        "    |       drive_path : Path to dataset file\n",
        "    |       dataset    : Dataset file name\n",
        "    | Return    :\n",
        "    |       dataset    : Dataset in dataframe format\n",
        "    *---------------------------------------------------------*/\n",
        "'''\n",
        "def load_dataset(drive_path, dataset):\n",
        "  loaded_dataset = pd.read_csv(drive_path + dataset)     # Read CSV file\n",
        "  print(\"=\"*40, \"\\n\", loaded_dataset)                    # Print the dataset that we load in previous step\n",
        "  return dataset"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWzDT9n4JwE1"
      },
      "source": [
        "# **Step 3: Understand and Pre-process Training Data, Testing Data and Validation Data**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPArHp40C_zM"
      },
      "source": [
        "### **Step 3.1: Pre-process Text**\n",
        "* Remove Non-alphanumeric Characters\n",
        "* Lower Case\n",
        "* Remove Leading and Trailing Whitespaces\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxOoCTTvDEhH"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- DATA_PRE-PROCESSING -------------\n",
        "    | Function  : data_pre-processing()\n",
        "    | Purpose   : Performs following pre-processing:\n",
        "    |              •\tRemove non-alphanumeric characters\n",
        "    |              •\tLower case\n",
        "    |              •\tRemove leading and trailing whitespaces\n",
        "    | Arguments : \n",
        "    |       text: Text to be pre-processed\n",
        "    | Return    :\n",
        "    |       text: Pre-processed text\n",
        "    *------------------------------------------------------------------------------------------------*/\n",
        "'''\n",
        "def data_pre_processing(text):\n",
        "      text = re.sub(r'[^A-Za-z0-9]+', ' ', text) # Remove non alphanumeric character\n",
        "      text = text.lower()                        # Lowercase all text\n",
        "      return text.strip()                        # Remove leading and trailing whitespaces"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNjSqTfyDWJ-"
      },
      "source": [
        "### **Step 3.2: Tokenize Text** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_Gls9kjKnZt"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- TOKENIZE_TEXT -------------\n",
        "    | Function  : data_tokenization()\n",
        "    | Purpose   : Tokenizes a Text\n",
        "    | Arguments : \n",
        "    |       text: Text to be tokenized\n",
        "    | Return    :\n",
        "    |       text: Tokenized Text\n",
        "    *------------------------------------------------------------------------------------------------*/\n",
        "'''\n",
        "def data_tokenization(s):\n",
        "      tok = spacy.load('en')                                             # Load english tokenizer from spacy\n",
        "      return [w.text.lower() for w in tok(data_pre_processing(s))]       # Apply pre-processing function (created in previous step) and tokenizer on text"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psc4OejpNdTK"
      },
      "source": [
        "### **Step 3.3: Build Training Data, Testing Data and Validation Data Objects**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QbnDKWrKxbj"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- BUILD_DATA_OBJECTS -------------\n",
        "    | Function  : data_objects()\n",
        "    | Purpose   : Build pre-processed and tokenized data objects\n",
        "    | Arguments : \n",
        "    |       drive_path : Path of the directory where data files are placed\n",
        "    | Return    :\n",
        "    |       pre_processed_training_data, pre_processed_validation_data, pre_processed_testing_data, LABEL, TEXT\n",
        "    *------------------------------------------------------------------------------------------------*/\n",
        "'''\n",
        "def data_objects(drive_path):\n",
        "  # Declared a Field object \n",
        "  # Field : A class that stores information about the way of preprocessing\n",
        "  TEXT  = Field(sequential= True, tokenize = data_tokenization, lower = True, include_lengths = True, batch_first = False, init_token = '<sos>', \n",
        "            eos_token = '<eos>')\n",
        "  LABEL = data.LabelField(dtype = torch.float)\n",
        "  # TabularDataset : Defines a dataset of columns. Create a TabularDataset given a path, file format, \n",
        "  # and Field list\n",
        "  training_data, validation_data, testing_data = TabularDataset.splits(path = drive_path + '/Data/',  \n",
        "                                                            train       = 'train_data.csv', \n",
        "                                                            validation  = 'validation_data.csv',\n",
        "                                                            test        = 'test_data.csv',\n",
        "                                                            format      = 'csv', \n",
        "                                                            fields      = [('Text', TEXT),('Gender', LABEL)], \n",
        "                                                            skip_header = True)\n",
        "  print(\"\\nPre-processed and Tokenized Training Data:\")\n",
        "  print(\"\\n=========================================\")\n",
        "  for i in range(len(training_data)):\n",
        "    print(training_data[i].Text)\n",
        "  print(\"\\nPre-processed and Tokenized Validation Data:\")\n",
        "  print(\"\\n=========================================\")\n",
        "  for i in range(len(validation_data)):\n",
        "    print(validation_data[i].Text)\n",
        "  print(\"\\nPre-processed and Tokenized Testing Data:\")\n",
        "  print(\"\\n=========================================\")\n",
        "  for i in range(len(testing_data)):\n",
        "      print(testing_data[i].Text)\n",
        "  \n",
        "  return training_data, validation_data, testing_data, LABEL, TEXT"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9AeRKT7N_Ak"
      },
      "source": [
        "### **Step 3.4: Load Pre-Trained Word Embedding Vectors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgwGVChRxHGC"
      },
      "source": [
        "#### Note\n",
        "**To download the Pre-trained Glove Model**\n",
        "* **In *Lecture 05 - Developing a Gender Identification (from Text) System using RNN-based Deep Neural Network* See *glove.6B.100d* File in *Pre-trained Glove Model* Folder**\n",
        "\n",
        "#### Note\n",
        "**For Lecture 05 - BI-LSTM (Data and Code)**\n",
        "* **To use the *glove.6B.100d* File (Pre-trained Glove Model) in your Code, Copy the *glove.6B.100d* File in *Lecture 05 - BI-LSTM (Data and Code)* Folder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMh7-DNUMaTP"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- LOAD_WORD_EMBEDDING_VECTORS -------------\n",
        "    | Function  : load_word_embedding_vectors()\n",
        "    | Purpose   : Load pre-trained word embedding vectors from memory\n",
        "    | Arguments : \n",
        "    |       drive_path : Path to word embedding vectors file\n",
        "    | Return    :\n",
        "    |       vectors     : Loaded word embedding vectors\n",
        "    *------------------------------------------------------------------------------------------------*/\n",
        "'''\n",
        "def load_word_embedding_vectors(drive_path):\n",
        "  # Load word embedding vectors from memory \n",
        "  # I have downloaded the Glove word embedding vectors 100d from internet and saved in my drive \n",
        "  # To use that, I simply give the path of that file and read file in my program using vocab.Vectors function\n",
        "  vectors = vocab.Vectors('glove.6B.100d.txt', drive_path)\n",
        "  return vectors"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2xwroDYROvr"
      },
      "source": [
        "### **Step 3.5: Build Vocabulary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVCVnAdaQWVh"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- BUILD_VOCABULARY -------------\n",
        "    | Function  : build_vocabulary()\n",
        "    | Purpose   : Build vocabulary from input data\n",
        "    | Arguments : \n",
        "    |       pre_processed_training_data   : Pre-processed training data\n",
        "    |     \n",
        "    |       vectors                       : Word embedding vectors \n",
        "    |       LABEL                         : LABEL object (Pre-processing applied on output)\n",
        "    |       TEXT                          : TEXT object (Pre-processing applied on input)\n",
        "    | Return    :\n",
        "    |       word_embeddings               : Word embedding vectors mapped on data\n",
        "    |       vocabulary_size               : Size of vocabulary\n",
        "    *------------------------------------------------------------------------------------------------*/\n",
        "'''\n",
        "\n",
        "def build_vocabulary(training_data, vectors, LABEL, TEXT):\n",
        "  TEXT.build_vocab(training_data, vectors=vectors, unk_init=torch.Tensor.normal_)   # Build vocabulary from training text\n",
        "  LABEL.build_vocab(training_data)                   # Build vocabulary from output / labels (Encode all labels)\n",
        "  \n",
        "  print(\"\\n=========================================\")\n",
        "  print(\"Output/Label word to index dictionary: \", LABEL.vocab.stoi)\n",
        "  print(\"\\n=========================================\")\n",
        "  print(\"Input Text word to index dictionary:\\n \", TEXT.vocab.stoi,\"\\n\")\n",
        "  \n",
        "  word_embeddings = TEXT.vocab.vectors   # Load vectors\n",
        "  vocabulary_size = len(TEXT.vocab)      # Size of vocabulary\n",
        "  return word_embeddings, vocabulary_size"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O1Rf_hqGrTA"
      },
      "source": [
        "# **Step 4: Represent Training Data, Testing Data and Validation Data in Machine Understandable Format**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4g4KhoqPAPV"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- REPRESENT_DATA_IN_MACHINE_UNDERSTANDABLE_FORMAT -------------\n",
        "    | Function  : data_iterators()\n",
        "    | Purpose   : To build input data (Training, validation and testing data) iterators \n",
        "    |             (It will convert data into machine understandable format and make data objects which we can iterate over during model training and testing)\n",
        "    | Arguments : \n",
        "    |       pre_processed_training_data   : Pre-processed training data\n",
        "    |       pre_processed_validation_data : Pre-processed validation data\n",
        "    |       pre_processed_testing_data    : Pre-processed testing data\n",
        "    | Return    :\n",
        "    |       training_iterator   : Training data iterator object\n",
        "    |       validation_iterator : Validation data iterator object\n",
        "    |       testing_iterator    : Testing data iterator object\n",
        "    *------------------------------------------------------------------------------------------------*/\n",
        "'''\n",
        "\n",
        "def data_iterators(training_data, validation_data, testing_data):\n",
        "  # Iterators handle numericalizing, batching, packaging. Basically, it does all the heavy lifting necessary \n",
        "  # to pass the data to a neural network\n",
        "  # BucketIterator : Defines an iterator that batches examples of similar lengths together to minimizes the amount of padding needed\n",
        "  # By using \"splits\" it applies processing steps on all datasets equally\n",
        "\n",
        "  training_iterator, validation_iterator, testing_iterator = data.BucketIterator.splits((training_data, validation_data, testing_data), batch_size=2, sort_key=lambda x: len(x.Text), repeat=False, shuffle=True,  sort_within_batch = True)\n",
        "  #print(\"\\nTraining Data Tensors Form\\n\")\n",
        "  #print(\"=\"*30, \"\\n\")\n",
        "  #for batch in training_iterator:\n",
        "  #  print(batch.Text)\n",
        "  #print(\"\\nValidation Data Tensors Form\\n\")\n",
        "  #print(\"=\"*30, \"\\n\")\n",
        "  #for batch in validation_iterator:\n",
        "  #  print(batch.Text)\n",
        "  #print(\"\\nTesting Data Tensors Form\\n\")\n",
        "  #print(\"=\"*30, \"\\n\")\n",
        "  #for batch in testing_iterator:\n",
        "  #  print(batch.Text)\n",
        "  return training_iterator, validation_iterator, testing_iterator"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYa50aXBG_iu",
        "outputId": "34af2027-02af-4fa9-c31c-9538306bd540"
      },
      "source": [
        "print(\"+============================Data Preparation============================+\\n\\n\")\n",
        "drive_path = '/content/drive/My Drive'\n",
        "print(\"---Step 2: Load Training Data, Testing Data and Validation Data---\")\n",
        "print(\"\\nTraining data before pre_processing\")\n",
        "original_training_data = load_dataset(drive_path, \"/Data/train_data.csv\")\n",
        "\n",
        "print(\"\\n\\nValidation data before pre_processing\")\n",
        "original_validation_data = load_dataset(drive_path, \"/Data/validation_data.csv\")\n",
        "\n",
        "print(\"\\n\\nTesting data before pre_processing\")\n",
        "original_testing_data = load_dataset(drive_path, \"/Data/test_data.csv\")\n",
        "print(\"\\n---Step 3: Understand and Pre-process Training Data, Testing Data and Validation Data---\")\n",
        "print(\"\\n---Step 4: Represent Training Data, Testing Data and Validation Data in Machine Understandable Format---\")\n",
        "preprocessed_training_data, preprocessed_validation_data, preprocessed_testing_data, LABEL, TEXT = data_objects(drive_path)\n",
        "# Load word embedding vectors from memory\n",
        "vectors = load_word_embedding_vectors(drive_path)\n",
        "# Build vocabulary\n",
        "word_embeddings, vocabulary_size = build_vocabulary(preprocessed_training_data, vectors, LABEL, TEXT)\n",
        "# Create iterator objects\n",
        "training_iterator, validation_iterator, testing_iterator = data_iterators(preprocessed_training_data, preprocessed_validation_data, preprocessed_testing_data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+============================Data Preparation============================+\n",
            "\n",
            "\n",
            "---Step 2: Load Training Data, Testing Data and Validation Data---\n",
            "\n",
            "Training data before pre_processing\n",
            "======================================== \n",
            "                                                  Text  Gender\n",
            "0   Your task is not to seek for love, but merely ...    Male\n",
            "1   You have to keep breaking your heart until it ...  Female\n",
            "2   Stop acting so small. You are the universe in ...    Male\n",
            "3   I’ve learned that people will forget what you ...  Female\n",
            "4                       What you seek is seeking you.    Male\n",
            "5   You may not control all the events that happen...  Female\n",
            "6   Don’t grieve. Anything you lose comes round in...    Male\n",
            "7   We delight in the beauty of the butterfly, but...  Female\n",
            "8   Yesterday I was clever, so I wanted to change ...    Male\n",
            "9   If you don’t like something, change it. If you...  Female\n",
            "10  You were born with wings, why prefer to crawl ...    Male\n",
            "11           We need much less than we think we need.  Female\n",
            "12  Don’t be satisfied with stories, how things ha...    Male\n",
            "13  If I am not good to myself, how can I expect a...  Female\n",
            "14  Everything that is made beautiful and fair and...    Male\n",
            "15  Never make someone a priority when all you are...  Female\n",
            "16  Why should I be unhappy? Every parcel of my be...    Male\n",
            "17  Hate, it has caused a lot of problems in the w...  Female\n",
            "18  Raise your words, not voice. It is rain that g...    Male\n",
            "19  If I can stop one heart from breaking, I shall...  Female\n",
            "20  Ignore those that make you fearful and sad, th...    Male\n",
            "21  There’s a world of difference between truth an...  Female\n",
            "22  There is a candle in your heart, ready to be k...    Male\n",
            "23  When someone shows you who they are, believe t...  Female\n",
            "24  Words are a pretext. It is the inner bond that...    Male\n",
            "25                        Forever is composed of nows  Female\n",
            "26  Goodbyes are only for those who love with thei...    Male\n",
            "27  That it will never come again is what makes li...  Female\n",
            "28  Set your life on fire. Seek those who fan your...    Male\n",
            "29  A little Madness in the Spring Is wholesome ev...  Female\n",
            "30     I know you’re tired but come, this is the way.    Male\n",
            "31            Saying nothing sometimes says the most.  Female\n",
            "32  This is love: to fly toward a secret sky, to c...    Male\n",
            "33  To live is so startling it leaves little time ...  Female\n",
            "34  The wound is the place where the light enters ...    Male\n",
            "35  I know nothing in the world that has as much p...  Female\n",
            "\n",
            "\n",
            "Validation data before pre_processing\n",
            "======================================== \n",
            "                                                 Text  Gender\n",
            "0  And so it is, that both the devil and the ange...    Male\n",
            "1  The soul should always stand ajar, ready to we...  Female\n",
            "2  A man is insensible to the relish of prosperit...    Male\n",
            "3     Truth is so rare, it is delightful to tell it.  Female\n",
            "\n",
            "\n",
            "Testing data before pre_processing\n",
            "======================================== \n",
            "                                                Quote  Gender\n",
            "0  Whenever you argue with another wiser than you...    Male\n",
            "1  Hold dear to your parents for it is a scary an...  Female\n",
            "2  The rose and the thorn, and sorrow and gladnes...    Male\n",
            "3  Instead of resisting to changes, surrender. Le...  Female\n",
            "4  Seek the wisdom that will untie your knot. See...    Male\n",
            "5  Surrendering is not a weakness. At the contrar...  Female\n",
            "6  Why do you stay in prison when the door is so ...    Male\n",
            "7  you have read thousands of books of knowledge,...  Female\n",
            "8  As you start to walk on the way, the way appears.    Male\n",
            "9  When the belly is empty, the body becomes spir...  Female\n",
            "\n",
            "---Step 3: Understand and Pre-process Training Data, Testing Data and Validation Data---\n",
            "\n",
            "---Step 4: Represent Training Data, Testing Data and Validation Data in Machine Understandable Format---\n",
            "\n",
            "Pre-processed and Tokenized Training Data:\n",
            "\n",
            "=========================================\n",
            "['your', 'task', 'is', 'not', 'to', 'seek', 'for', 'love', 'but', 'merely', 'to', 'seek', 'and', 'find', 'all', 'the', 'barriers', 'within', 'yourself', 'that', 'you', 'have', 'built', 'against', 'it']\n",
            "['you', 'have', 'to', 'keep', 'breaking', 'your', 'heart', 'until', 'it', 'opens']\n",
            "['stop', 'acting', 'so', 'small', 'you', 'are', 'the', 'universe', 'in', 'ecstatic', 'motion']\n",
            "['i', 've', 'learned', 'that', 'people', 'will', 'forget', 'what', 'you', 'said', 'people', 'will', 'forget', 'what', 'you', 'did', 'but', 'people', 'will', 'never', 'forget', 'how', 'you', 'made', 'them', 'feel']\n",
            "['what', 'you', 'seek', 'is', 'seeking', 'you']\n",
            "['you', 'may', 'not', 'control', 'all', 'the', 'events', 'that', 'happen', 'to', 'you', 'but', 'you', 'can', 'decide', 'not', 'to', 'be', 'reduced', 'by', 'them']\n",
            "['don', 't', 'grieve', 'anything', 'you', 'lose', 'comes', 'round', 'in', 'another', 'form']\n",
            "['we', 'delight', 'in', 'the', 'beauty', 'of', 'the', 'butterfly', 'but', 'rarely', 'admit', 'the', 'changes', 'it', 'has', 'gone', 'through', 'to', 'achieve', 'that', 'beauty']\n",
            "['yesterday', 'i', 'was', 'clever', 'so', 'i', 'wanted', 'to', 'change', 'the', 'world', 'today', 'i', 'am', 'wise', 'so', 'i', 'am', 'changing', 'myself']\n",
            "['if', 'you', 'don', 't', 'like', 'something', 'change', 'it', 'if', 'you', 'can', 't', 'change', 'it', 'change', 'your', 'attitude']\n",
            "['you', 'were', 'born', 'with', 'wings', 'why', 'prefer', 'to', 'crawl', 'through', 'life']\n",
            "['we', 'need', 'much', 'less', 'than', 'we', 'think', 'we', 'need']\n",
            "['don', 't', 'be', 'satisfied', 'with', 'stories', 'how', 'things', 'have', 'gone', 'with', 'others', 'unfold', 'your', 'own', 'myth']\n",
            "['if', 'i', 'am', 'not', 'good', 'to', 'myself', 'how', 'can', 'i', 'expect', 'anyone', 'else', 'to', 'be', 'good', 'to', 'me']\n",
            "['everything', 'that', 'is', 'made', 'beautiful', 'and', 'fair', 'and', 'lovely', 'is', 'made', 'for', 'the', 'eye', 'of', 'one', 'who', 'sees']\n",
            "['never', 'make', 'someone', 'a', 'priority', 'when', 'all', 'you', 'are', 'to', 'them', 'is', 'an', 'option']\n",
            "['why', 'should', 'i', 'be', 'unhappy', 'every', 'parcel', 'of', 'my', 'being', 'is', 'in', 'full', 'bloom']\n",
            "['hate', 'it', 'has', 'caused', 'a', 'lot', 'of', 'problems', 'in', 'the', 'world', 'but', 'has', 'not', 'solved', 'one', 'yet']\n",
            "['raise', 'your', 'words', 'not', 'voice', 'it', 'is', 'rain', 'that', 'grows', 'flowers', 'not', 'thunder']\n",
            "['if', 'i', 'can', 'stop', 'one', 'heart', 'from', 'breaking', 'i', 'shall', 'not', 'live', 'in', 'vain']\n",
            "['ignore', 'those', 'that', 'make', 'you', 'fearful', 'and', 'sad', 'that', 'degrade', 'you', 'back', 'towards', 'disease', 'and', 'death']\n",
            "['there', 's', 'a', 'world', 'of', 'difference', 'between', 'truth', 'and', 'facts', 'facts', 'can', 'obscure', 'the', 'truth']\n",
            "['there', 'is', 'a', 'candle', 'in', 'your', 'heart', 'ready', 'to', 'be', 'kindled', 'there', 'is', 'a', 'void', 'in', 'your', 'soul', 'ready', 'to', 'be', 'filled', 'you', 'feel', 'it', 'don', 't', 'you']\n",
            "['when', 'someone', 'shows', 'you', 'who', 'they', 'are', 'believe', 'them', 'the', 'first', 'time']\n",
            "['words', 'are', 'a', 'pretext', 'it', 'is', 'the', 'inner', 'bond', 'that', 'draws', 'one', 'person', 'to', 'another', 'not', 'words']\n",
            "['forever', 'is', 'composed', 'of', 'nows']\n",
            "['goodbyes', 'are', 'only', 'for', 'those', 'who', 'love', 'with', 'their', 'eyes', 'because', 'for', 'those', 'who', 'love', 'with', 'heart', 'and', 'soul', 'there', 'is', 'no', 'such', 'thing', 'as', 'separation']\n",
            "['that', 'it', 'will', 'never', 'come', 'again', 'is', 'what', 'makes', 'life', 'so', 'sweet']\n",
            "['set', 'your', 'life', 'on', 'fire', 'seek', 'those', 'who', 'fan', 'your', 'flames']\n",
            "['a', 'little', 'madness', 'in', 'the', 'spring', 'is', 'wholesome', 'even', 'for', 'the', 'king']\n",
            "['i', 'know', 'you', 're', 'tired', 'but', 'come', 'this', 'is', 'the', 'way']\n",
            "['saying', 'nothing', 'sometimes', 'says', 'the', 'most']\n",
            "['this', 'is', 'love', 'to', 'fly', 'toward', 'a', 'secret', 'sky', 'to', 'cause', 'a', 'hundred', 'veils', 'to', 'fall', 'each', 'moment', 'first', 'to', 'let', 'go', 'of', 'life', 'finally', 'to', 'take', 'a', 'step', 'without', 'feet']\n",
            "['to', 'live', 'is', 'so', 'startling', 'it', 'leaves', 'little', 'time', 'for', 'anything', 'else']\n",
            "['the', 'wound', 'is', 'the', 'place', 'where', 'the', 'light', 'enters', 'you']\n",
            "['i', 'know', 'nothing', 'in', 'the', 'world', 'that', 'has', 'as', 'much', 'power', 'as', 'a', 'word', 'sometimes', 'i', 'write', 'one', 'and', 'i', 'look', 'at', 'it', 'until', 'it', 'begins', 'to', 'shine']\n",
            "\n",
            "Pre-processed and Tokenized Validation Data:\n",
            "\n",
            "=========================================\n",
            "['and', 'so', 'it', 'is', 'that', 'both', 'the', 'devil', 'and', 'the', 'angelic', 'spirits', 'present', 'us', 'with', 'objects', 'of', 'desire', 'to', 'awaken', 'our', 'power', 'of', 'choice']\n",
            "['the', 'soul', 'should', 'always', 'stand', 'ajar', 'ready', 'to', 'welcome', 'the', 'ecstatic', 'experience']\n",
            "['a', 'man', 'is', 'insensible', 'to', 'the', 'relish', 'of', 'prosperity', 'til', 'he', 'has', 'tasted', 'adversity']\n",
            "['truth', 'is', 'so', 'rare', 'it', 'is', 'delightful', 'to', 'tell', 'it']\n",
            "\n",
            "Pre-processed and Tokenized Testing Data:\n",
            "\n",
            "=========================================\n",
            "['whenever', 'you', 'argue', 'with', 'another', 'wiser', 'than', 'yourself', 'in', 'order', 'that', 'others', 'may', 'admire', 'your', 'wisdom', 'they', 'will', 'discover', 'your', 'ignorance']\n",
            "['hold', 'dear', 'to', 'your', 'parents', 'for', 'it', 'is', 'a', 'scary', 'and', 'confusing', 'world', 'without', 'them']\n",
            "['the', 'rose', 'and', 'the', 'thorn', 'and', 'sorrow', 'and', 'gladness', 'are', 'linked', 'together']\n",
            "['instead', 'of', 'resisting', 'to', 'changes', 'surrender', 'let', 'life', 'be', 'with', 'you', 'not', 'against', 'you', 'if', 'you', 'think', 'my', 'life', 'will', 'be', 'upside', 'down', 'don', 't', 'worry', 'how', 'do', 'you', 'know', 'down', 'is', 'not', 'better', 'than', 'upside']\n",
            "['seek', 'the', 'wisdom', 'that', 'will', 'untie', 'your', 'knot', 'seek', 'the', 'path', 'that', 'demands', 'your', 'whole', 'being']\n",
            "['surrendering', 'is', 'not', 'a', 'weakness', 'at', 'the', 'contrary', 'it', 'is', 'strength', 'the', 'surrender', 'stops', 'living', 'in', 'boiling', 'water', 'and', 'starts', 'living', 'in', 'a', 'secure', 'place']\n",
            "['why', 'do', 'you', 'stay', 'in', 'prison', 'when', 'the', 'door', 'is', 'so', 'wide', 'open']\n",
            "['you', 'have', 'read', 'thousands', 'of', 'books', 'of', 'knowledge', 'have', 'you', 'ever', 'tried', 'to', 'read', 'your', 'ownself']\n",
            "['as', 'you', 'start', 'to', 'walk', 'on', 'the', 'way', 'the', 'way', 'appears']\n",
            "['when', 'the', 'belly', 'is', 'empty', 'the', 'body', 'becomes', 'spirit', 'and', 'when', 'it', 'is', 'full', 'the', 'spirit', 'becomes', 'body']\n",
            "\n",
            "=========================================\n",
            "Output/Label word to index dictionary:  defaultdict(<function _default_unk_index at 0x7fd7259ec9d8>, {'Female': 0, 'Male': 1})\n",
            "\n",
            "=========================================\n",
            "Input Text word to index dictionary:\n",
            "  defaultdict(<function _default_unk_index at 0x7fd7259ec9d8>, {'<unk>': 0, '<pad>': 1, '<sos>': 2, '<eos>': 3, 'you': 4, 'to': 5, 'the': 6, 'is': 7, 'i': 8, 'it': 9, 'a': 10, 'that': 11, 'in': 12, 'not': 13, 'your': 14, 'and': 15, 'of': 16, 'be': 17, 'but': 18, 'for': 19, 'are': 20, 'can': 21, 'one': 22, 'so': 23, 't': 24, 'who': 25, 'with': 26, 'change': 27, 'don': 28, 'has': 29, 'heart': 30, 'if': 31, 'life': 32, 'love': 33, 'seek': 34, 'them': 35, 'there': 36, 'those': 37, 'we': 38, 'what': 39, 'will': 40, 'world': 41, 'all': 42, 'am': 43, 'as': 44, 'forget': 45, 'have': 46, 'how': 47, 'made': 48, 'never': 49, 'people': 50, 'words': 51, 'another': 52, 'anything': 53, 'beauty': 54, 'breaking': 55, 'come': 56, 'else': 57, 'facts': 58, 'feel': 59, 'first': 60, 'gone': 61, 'good': 62, 'know': 63, 'little': 64, 'live': 65, 'make': 66, 'much': 67, 'myself': 68, 'need': 69, 'nothing': 70, 'ready': 71, 'someone': 72, 'sometimes': 73, 'soul': 74, 'stop': 75, 'this': 76, 'through': 77, 'time': 78, 'truth': 79, 'until': 80, 'when': 81, 'why': 82, 'achieve': 83, 'acting': 84, 'admit': 85, 'again': 86, 'against': 87, 'an': 88, 'anyone': 89, 'at': 90, 'attitude': 91, 'back': 92, 'barriers': 93, 'beautiful': 94, 'because': 95, 'begins': 96, 'being': 97, 'believe': 98, 'between': 99, 'bloom': 100, 'bond': 101, 'born': 102, 'built': 103, 'butterfly': 104, 'by': 105, 'candle': 106, 'cause': 107, 'caused': 108, 'changes': 109, 'changing': 110, 'clever': 111, 'comes': 112, 'composed': 113, 'control': 114, 'crawl': 115, 'death': 116, 'decide': 117, 'degrade': 118, 'delight': 119, 'did': 120, 'difference': 121, 'disease': 122, 'draws': 123, 'each': 124, 'ecstatic': 125, 'enters': 126, 'even': 127, 'events': 128, 'every': 129, 'everything': 130, 'expect': 131, 'eye': 132, 'eyes': 133, 'fair': 134, 'fall': 135, 'fan': 136, 'fearful': 137, 'feet': 138, 'filled': 139, 'finally': 140, 'find': 141, 'fire': 142, 'flames': 143, 'flowers': 144, 'fly': 145, 'forever': 146, 'form': 147, 'from': 148, 'full': 149, 'go': 150, 'goodbyes': 151, 'grieve': 152, 'grows': 153, 'happen': 154, 'hate': 155, 'hundred': 156, 'ignore': 157, 'inner': 158, 'keep': 159, 'kindled': 160, 'king': 161, 'learned': 162, 'leaves': 163, 'less': 164, 'let': 165, 'light': 166, 'like': 167, 'look': 168, 'lose': 169, 'lot': 170, 'lovely': 171, 'madness': 172, 'makes': 173, 'may': 174, 'me': 175, 'merely': 176, 'moment': 177, 'most': 178, 'motion': 179, 'my': 180, 'myth': 181, 'no': 182, 'nows': 183, 'obscure': 184, 'on': 185, 'only': 186, 'opens': 187, 'option': 188, 'others': 189, 'own': 190, 'parcel': 191, 'person': 192, 'place': 193, 'power': 194, 'prefer': 195, 'pretext': 196, 'priority': 197, 'problems': 198, 'rain': 199, 'raise': 200, 'rarely': 201, 're': 202, 'reduced': 203, 'round': 204, 's': 205, 'sad': 206, 'said': 207, 'satisfied': 208, 'saying': 209, 'says': 210, 'secret': 211, 'seeking': 212, 'sees': 213, 'separation': 214, 'set': 215, 'shall': 216, 'shine': 217, 'should': 218, 'shows': 219, 'sky': 220, 'small': 221, 'solved': 222, 'something': 223, 'spring': 224, 'startling': 225, 'step': 226, 'stories': 227, 'such': 228, 'sweet': 229, 'take': 230, 'task': 231, 'than': 232, 'their': 233, 'they': 234, 'thing': 235, 'things': 236, 'think': 237, 'thunder': 238, 'tired': 239, 'today': 240, 'toward': 241, 'towards': 242, 'unfold': 243, 'unhappy': 244, 'universe': 245, 'vain': 246, 've': 247, 'veils': 248, 'voice': 249, 'void': 250, 'wanted': 251, 'was': 252, 'way': 253, 'were': 254, 'where': 255, 'wholesome': 256, 'wings': 257, 'wise': 258, 'within': 259, 'without': 260, 'word': 261, 'wound': 262, 'write': 263, 'yesterday': 264, 'yet': 265, 'yourself': 266}) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA28a28VbwG3"
      },
      "source": [
        "# **Step 5: Execute the Training Phase**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQVos9zwx1lF"
      },
      "source": [
        "### **Step 5.1:Model Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CRSleE1TuGr"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- MODEL_ARCHITECTURE -------------\n",
        "    | Class     : BLSTM()\n",
        "    | Purpose   : To build the architecture of model to be trained\n",
        "    *---------------------------------------------------------\n",
        "    | nn.Module : Base class for all neural network modules. Your models should also subclass this class.\n",
        "    |\n",
        "    | Arguments:\n",
        "    |      output_dim    : 1 (female or male). For output layer number of nodes in output layer will be same as \n",
        "    |                      number of outputs required in your problem\n",
        "    |\t     hidden_dim    : Size of the hidden layer. Here size of hidden_state of the lstm\n",
        "    | \t\t input_dim     : Size of the vocabulary containing unique words. Total number of unique words in sample data \n",
        "    |\t\t   embedding_dim : Size of each embedding vector. Here embeddding dimension of GloVe word embedding \n",
        "    |                      vectors is 100 so embedding_dim = 100\n",
        "    |\t\t   weights       : Pre-trained GloVe word_embeddings which we will use to create our word_embedding look-up table\n",
        "    *------------------------------------------------------------------------------------\n",
        "    | Function  : forward()\n",
        "    | Purpose   : This function will automatically start foward propogation when model object is called\n",
        "    | Arguments :\n",
        "    |     text  : Input text of shape = (num_sequences, batch_size)\t\n",
        "\t  | Return:\n",
        "\t  |     hidden_state : Final model state learned from input text\n",
        "    ------------------------------------------------------------------------------\n",
        "'''\n",
        "\n",
        "class BLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, word_embeddings, n_layers, n_directions):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.n_layers     = n_layers\n",
        "        self.n_directions = n_directions\n",
        "        self.hidden_dim   = hidden_dim\n",
        "        self.embedding_layer = nn.Embedding(input_dim, embedding_dim)          # Embedding layer shape\n",
        "        # Assign pre-trained weights and update the weights during backpropagation \n",
        "        self.embedding_layer.weight = nn.Parameter(word_embeddings, requires_grad = True)      \n",
        "        self.blstm_layer       = nn.LSTM(embedding_dim, hidden_dim, num_layers = n_layers, bidirectional = True) # We can implement multiple layers of lstm simply by changing num_layers value \n",
        "        self.linear_layer      = nn.Linear(hidden_dim * 2, output_dim)               # Shape of linear layer\n",
        "        \n",
        "    def forward(self, text, seq_length):\n",
        "\n",
        "        batch_size = text.shape[1]\n",
        "        h_0, c_0 = self.init_hidden(batch_size)   # Initialize first hidden state to all zeros\n",
        "        \n",
        "        # Here we will map all the indexes present in the input sequence to the corresponding \n",
        "\t\t    # word vector using our trained word_embedddings.\n",
        "\t      # embedded input of shape = (num_sequences, batch_size, embedding_dimension)\n",
        "        embedded_vectors = self.embedding_layer(text)\n",
        "        #print(embedded_vectors)                    \n",
        "        \n",
        "        packed_embedded_vectors = nn.utils.rnn.pack_padded_sequence(embedded_vectors, seq_length)    # pack input sequence\n",
        "        \n",
        "        \n",
        "        packed_output_state, (hidden_state, cell_state) = self.blstm_layer(packed_embedded_vectors, (h_0, c_0))  # Apply blstm layer and start learning sequence of words\n",
        "        \n",
        "        output_state, output_seq_length = nn.utils.rnn.pad_packed_sequence(packed_output_state)  # unpack sequence\n",
        "        \n",
        "        hidden_state = torch.cat((hidden_state[-2,:,:], hidden_state[-1,:,:]), dim = 1)\n",
        "        hidden_state = self.linear_layer(hidden_state)      # Apply the linear layer on hidden_state / context vector\n",
        "        return torch.sigmoid(hidden_state)\n",
        "    def init_hidden(self,batch_size):\n",
        "        h_0 = torch.zeros(self.n_layers * self.n_directions, batch_size, self.hidden_dim)\n",
        "        c_0 = torch.zeros(self.n_layers * self.n_directions, batch_size, self.hidden_dim)\n",
        "        return h_0, c_0"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvs0X3gGx5mt"
      },
      "source": [
        "### **Step 5.2: Hyperparameters Settings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CefOUiYxTuLS"
      },
      "source": [
        "'''\n",
        "/*---------------- INITIALIZE_PARAMETERS ------------------\n",
        "'''\n",
        "input_dimension      = len(TEXT.vocab)\n",
        "embedding_dimension  = 100\n",
        "hidden_dimension     = 100\n",
        "output_dimension     = 1\n",
        "number_of_layers     = 4\n",
        "number_of_directions = 2\n",
        "number_of_epochs     = 10"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei0-8uIEyg8S"
      },
      "source": [
        "### **Step 5.3: Create Model Object**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q3WynYHydya",
        "outputId": "18b9c293-faa0-442f-b978-be31ba781921"
      },
      "source": [
        "\"\"\"\n",
        "/* ----------------------- MODEL_OBJECT -----------------\n",
        "| Create the object of model class and pass parameters required: BLSTM()\n",
        "|           Arguments : \n",
        "|               input_dimension     : (integer) dimension of input layer(vocabulary size)\n",
        "|               output_dimension    : (integer) number of output layer nodes \n",
        "|               hidden_dimension    : (integer) number of nodes/units in hidden layer\n",
        "|               embedding_dimension : (integer) dimension of embedded vector\n",
        "*-------------------------------------------------------*/\n",
        "\"\"\"\n",
        "model = BLSTM(input_dimension, embedding_dimension, hidden_dimension, output_dimension, word_embeddings, number_of_layers, number_of_directions)\n",
        "model"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BLSTM(\n",
              "  (embedding_layer): Embedding(267, 100)\n",
              "  (blstm_layer): LSTM(100, 100, num_layers=4, bidirectional=True)\n",
              "  (linear_layer): Linear(in_features=200, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSLie03NX69g"
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model.embedding_layer.weight.data[UNK_IDX] = torch.zeros(embedding_dimension)\n",
        "model.embedding_layer.weight.data[PAD_IDX] = torch.zeros(embedding_dimension)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wel_CVE9Hq7h"
      },
      "source": [
        "### **Step 5.4: Initialize Optimizer and Loss Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSnSintDHp-Y"
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr = 1e-3)   # Initialize the optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()                     # Intialize loss function"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4EbzTf2yDXv"
      },
      "source": [
        "### **Step 5.5: Evaluation Measure**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUv7C61bUCxh"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- CALCULATE_ACCURACY -------------\n",
        "    | Function  : calculate_accuracy()\n",
        "    | Purpose   : Calculate accuracy score\n",
        "    | Arguments : \n",
        "    |       prediction : Predicted values\n",
        "    |       label      : Actual values\n",
        "    | Return    :\n",
        "    |       accuracy   : Accuracy score\n",
        "    *---------------------------------------------------------*/\n",
        "'''\n",
        "\n",
        "def calculate_accuracy(prediction, label):\n",
        "\n",
        "    rounded_preds = torch.round(prediction)                     # Round predictions to the closest integer\n",
        "    correct       = (rounded_preds == label).float()            # Convert into float for division \n",
        "    accuracy      = correct.sum() / len(correct)                # Average accuracy\n",
        "    return accuracy"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NetB7IAkkQBZ"
      },
      "source": [
        "### **Step 5.6: Calculate Epoch Elapsed Time**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooQgi4hSkOzY"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- EPOCH_TIME_CALCULATION -------------\n",
        "    | Function  : epoch_time()\n",
        "    | Purpose   : Calculate time elapsed in each epoch\n",
        "    | Arguments : \n",
        "    |        start_time   : Time when an epoch's execution starts\n",
        "    |        end_time     : Time when an epoch's execution end\n",
        "    | Return    :\n",
        "    |        elapsed_mins : Time consumed by one epoch in minutes\n",
        "    |        elapsed_secs : Time consumed by one epoch in seconds\n",
        "    *---------------------------------------------------------*/\n",
        "'''\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time                   # Time elapsed by one epoch \n",
        "    elapsed_mins = int(elapsed_time / 60)                  # Convert time in minutes\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60)) # Convert time in seconds\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaCrVXFHk3Un"
      },
      "source": [
        "### **Step 5.7: Train Model** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCEM1y30UCtn"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- TRAIN_MODEL -------------\n",
        "    | Function  : train()\n",
        "    | Purpose   : Train Model\n",
        "    | Arguments : \n",
        "    |        model                 : Model object\n",
        "    |        training_data_iterator: Training data iterator object\n",
        "    |        optimizer             : Optimization algorithm\n",
        "    |        criterion             : Loss funtion\n",
        "    | Return    :\n",
        "    |        epoch_loss            : Train data loss at each epoch\n",
        "    |        epoch_accuracy        : Train data accuracy at each epoch\n",
        "    *---------------------------------------------------------*/\n",
        "'''\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss      = 0                                                 # Initialize epoch loss to 0\n",
        "    epoch_accuracy  = 0                                                 # Initialize epoch accuracy to 0\n",
        "    \n",
        "    model.train()                                                       # Start model training mode\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()                                           # Clear all optimized gradients\n",
        "        text, seq_length = batch.Text\n",
        "        predictions = model(text, seq_length).squeeze(1)                # Make model predictions on training data\n",
        "        \n",
        "        loss     = criterion(predictions, batch.Gender)                 # Calculate loss for each batch in epoch\n",
        "        accuracy = calculate_accuracy(predictions, batch.Gender)        # Calculate accuracy for each batch in epoch\n",
        "        \n",
        "        loss.backward()                                                  # Start backward propogation\n",
        "        optimizer.step()                                                 # Optimization of parameters\n",
        "        \n",
        "        epoch_loss      += loss.item()                                   # Add loss for all batches in one epoch\n",
        "        epoch_accuracy  += accuracy.item()                               # Add accuracy for all batches in one epoch\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_accuracy / len(iterator)    # Average loss and accuracy for one epoch and return"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkJM892QCf8n"
      },
      "source": [
        "### **Step 5.8: Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs2t_LSsCflh"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- SAVE_MODEL -------------\n",
        "    | Function  : save_model()\n",
        "    | Purpose   : Save a trained model on your hard disk\n",
        "    | Arguments : \n",
        "    |        drive_path: Path to the directory where the trained model will be saved\n",
        "    | Return    :\n",
        "    |        Trained model will be saved on hard disk\n",
        "    *---------------------------------------------------------*/\n",
        "\n",
        "'''\n",
        "def save_model(drive_path):\n",
        "  torch.save(model.state_dict(), drive_path + '/best-blstm-model.pt')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnUl6WU3mqN8"
      },
      "source": [
        "### **Evaluate Model**\n",
        "\n",
        "\n",
        "*   **Function to be used in Validation and Test Phase**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Xu03MMmmsHS"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- Evaluate_MODEL -------------\n",
        "    | Function  : evaluate()\n",
        "    | Purpose   : Function to be used in Validation and Test Phase\n",
        "    | Arguments : \n",
        "    |        model                : Model object\n",
        "    |        data_iterator:  Data iterator object\n",
        "    | Return    :\n",
        "    |        epoch_loss           : Data loss at each epoch\n",
        "    |        epoch_accuracy       : Data accuracy at each epoch\n",
        "    *---------------------------------------------------------*/\n",
        "'''\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss     = 0      # Initialize epoch loss to 0\n",
        "    epoch_accuracy = 0      # Initialize epoch accuracy to 0\n",
        "    model.eval()            # Start model evaluation mode\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "\n",
        "            text, seq_length = batch.Text\n",
        "            predictions = model(text, seq_length).squeeze(1)                # Make model predictions on data\n",
        "            loss = criterion(predictions, batch.Gender)               # Calculate loss for each batch in epoch\n",
        "            \n",
        "            accuracy = calculate_accuracy(predictions, batch.Gender)  # Calculate accuracy for each batch in epoch\n",
        "            epoch_loss += loss.item()                                 # Add loss for all batches, in one epoch\n",
        "            epoch_accuracy += accuracy.item()                         # Add accuracy for all batches in one epoch\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_accuracy / len(iterator)  # Average loss and accuracy for one epoch and return"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNviSRgznIRm"
      },
      "source": [
        "# **Step 6: Execute the Validation Phase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m7Zgk3PnHAp"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- VALIDATE_MODEL -------------\n",
        "    | Function  : validation()\n",
        "    | Purpose   : Evalaute the performance of a trained  model\n",
        "    | Arguments : \n",
        "    |        model                   : Model object\n",
        "    |        validation_data_iterator: Validation data iterator object\n",
        "    |        criterion               : Loss function\n",
        "    | Return    :\n",
        "    |        epoch_loss           : Validation data loss at each epoch\n",
        "    |        epoch_accuracy       : Validation data accuracy at each epoch\n",
        "    *---------------------------------------------------------*/\n",
        "'''\n",
        "\n",
        "def validation(model, validation_iterator, criterion):\n",
        "      best_validation_loss = float('inf')                                                        # Declare best validation loss variable\n",
        "      validation_loss, validation_accuracy = evaluate(model, validation_iterator, criterion)     # Start model validation phase\n",
        "      \n",
        "      if validation_loss < best_validation_loss:\n",
        "        best_validation_loss = validation_loss\n",
        "        save_model(drive_path)                                   # Save model on epoch where the validation loss is lowest\n",
        "      return validation_loss, validation_accuracy"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7eq9ITswjkj"
      },
      "source": [
        "# **Step 7: Execute the Testing Phase**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMXlZ5lCJhjT"
      },
      "source": [
        "### **Step 7.1: Load Saved Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G3r9plWJfG8"
      },
      "source": [
        "\"\"\"\n",
        "/*---------------------- LOAD_SAVED_MODEL ----------\n",
        "|  Function  : load_model()\n",
        "|  Purpose   : Method to load previously saved model\n",
        "|  Arguments :\n",
        "|       drive_path : Path of directory where model is saved\n",
        "|  Return    :\n",
        "|              Saved model will be loaded in memory\n",
        "*---------------------------------------------------------*/\n",
        "\"\"\"\n",
        "def load_model(drive_path):\n",
        "  return model.load_state_dict(torch.load(drive_path + '/best-blstm-model.pt'))  # Load pre-trained model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3Ok_7ubwpra"
      },
      "source": [
        "### **Step 7.2: Test Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G73v1toWUCpe"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- TEST_MODEL -------------\n",
        "    | Function  : test()\n",
        "    | Purpose   : Evalaute the performance of a trained  model\n",
        "    | Arguments : \n",
        "    |        model                : Model object\n",
        "    |        testing_data_iterator: Test data iterator object\n",
        "    |        criterion            : Loss function\n",
        "    | Return    :\n",
        "    |        epoch_loss           : Test data loss at each epoch\n",
        "    |        epoch_accuracy       : Test data accuracy at each epoch\n",
        "    *---------------------------------------------------------*/\n",
        "'''\n",
        "\n",
        "def test(model, testing_iterator, criterion):\n",
        "  load_model(drive_path)\n",
        "  testing_loss, testing_accuracy = evaluate(model, testing_iterator, criterion)   # Start model testing\n",
        "  return testing_loss, testing_accuracy"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq6v9RkDy54S"
      },
      "source": [
        "# **Step 8: Execute the Application Phase**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz1ncaC92u7G"
      },
      "source": [
        "### **Step 8.1: Take Input from User and Convert it into Feature Vector Same as Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52dLFalC2uKE"
      },
      "source": [
        "''' \n",
        "    /*----------------------------- USER_INPUT -------------\n",
        "    | Function  : take_user_input()\n",
        "    | Purpose   : Take unseen input from user\n",
        "    | Arguments : \n",
        "    |        TEXT : Field object to apply pre-processing on input text (same as sample data)\n",
        "    | Return    :\n",
        "    |        user_comment_tensor : User input in machine understandable format\n",
        "    |----------------------------------------------------------\n",
        "    | - Let us now predict the gender on a single comment for the real time evaluation purpose \n",
        "    | 1 : Take input from user\n",
        "    | 2 : Preprocess the user input\n",
        "    | 3 : Fit vocabulary previously made for sample data on user input. The indexes assigned for words in \n",
        "    |     sample data will be assigned to user input. Words in user input that does not appear in \n",
        "    |     sample data will have zero value\n",
        "    | 4 : Convert user input to an array\n",
        "    | 5 : Make tensor from array. As pytorch only work with tensors\n",
        "    *---------------------------------------------------------*/\n",
        "\n",
        "'''\n",
        "\n",
        "def take_user_input(TEXT):\n",
        "  user_comment = input(\"Enter comment: \") \n",
        "  \n",
        "  #Preprocess user input\n",
        "  preprocessed_user_comment = TEXT.preprocess(user_comment)\n",
        "  preprocessed_user_comment = [TEXT.init_token] + preprocessed_user_comment + [TEXT.eos_token]\n",
        "  user_comment_vocabulary = [TEXT.vocab.stoi[x] for x in preprocessed_user_comment]\n",
        "  user_comment_array = np.asarray(user_comment_vocabulary)\n",
        "  user_comment_tensor = torch.LongTensor(user_comment_array).unsqueeze(1)\n",
        "  user_comment_tensor = user_comment_tensor\n",
        "  seq_length          = [len(user_comment_tensor)]\n",
        "  seq_length          = torch.LongTensor(seq_length)\n",
        "\n",
        "  print(\"\\nPreprocessed User_input:\\n==========================\")\n",
        "  print(preprocessed_user_comment)\n",
        "  print(\"\\nIdx stored in vocab, corresponding to each word in user_input:\\n==========================\")\n",
        "  print(user_comment_vocabulary) \n",
        "  print(\"\\nUser_input as a tensor:\\n==========================\" )\n",
        "  print(user_comment_tensor)\n",
        "  \n",
        "  return user_comment_tensor, seq_length"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHSMkFxo0nX7"
      },
      "source": [
        "### **Step 8.2: Load Saved Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-TRL13RvmSA"
      },
      "source": [
        "\"\"\"\n",
        "/*---------------------- LOAD_SAVED_MODEL ----------\n",
        "|  Function  : load_model()\n",
        "|  Purpose   : Method to load previously saved model\n",
        "|  Arguments :\n",
        "|       drive_path : Path of directory where model is saved\n",
        "|  Return    :\n",
        "|              Saved model will be loaded in memory\n",
        "*---------------------------------------------------------*/\n",
        "\"\"\"\n",
        "def load_model(drive_path):\n",
        "  return model.load_state_dict(torch.load(drive_path + '/best-blstm-model.pt'))  # Load pre-trained model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc0yXZO627el"
      },
      "source": [
        "### **Step 8.3: Model Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozMmz-GatVCc"
      },
      "source": [
        "\"\"\"\n",
        "/*----------------------- MODEL_PREDICTION --------\n",
        "|  Function  : model_prediction()\n",
        "|  Purpose   : Use trained model to predict the output of unseen instances\n",
        "|  Arguments : \n",
        "|       user_input : Input taken from user\n",
        "|       drive_path : Path of the directory where trained model is saved\n",
        "|  Return    : \n",
        "|       Gender     : Prediction \n",
        "*--------------------------------------------------\n",
        "|   1. Set the model to evaluation mode\n",
        "|   2. Set all the gradients to zero\n",
        "|   3. Apply trained model on user input\n",
        "|   \n",
        "|   4. torch.round() : \n",
        "|         Return the value rounded to the closest integer (0 or 1)\n",
        "|   5. If returned output is 1 Print \"Male\" else \"Female\"\n",
        "*-------------------------------------------------*/   \n",
        "\"\"\"\n",
        "\n",
        "def model_predictions(user_input, seq_length, drive_path):\n",
        "  # Evaluate model\n",
        "  load_model(drive_path)  # Load model from memory to test its performance\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    #print(Evaluate_text_tensor)\n",
        "    # Model Prediction\n",
        "    \n",
        "    out = model(user_input, seq_length)\n",
        "  \n",
        "  if (torch.round(out) == 1):\n",
        "    Gender = \"Male\"\n",
        "  else:\n",
        "    Gender = \"Female\"\n",
        "  return Gender"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzvwbR2VUfJN"
      },
      "source": [
        "# **Main Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7jCJVmFdQZZ",
        "outputId": "1707dfcd-de21-4950-fc66-61a4e831d277"
      },
      "source": [
        "print(\"\\n+=====================Execute the Training and Validation Phase=====================+\\n\\n\")\n",
        "# Step 5: Execute the Training Phase\n",
        "\n",
        "for epoch in range(number_of_epochs):\n",
        "\n",
        "    start_time = time.time()                                    # Start time when one epoch will start executing\n",
        "    \n",
        "    training_loss, training_accuracy     = train(model, training_iterator, optimizer, criterion)   # Start model training\n",
        "    \n",
        "    # Step 7: Execute the Validation Phase\n",
        "    validation_loss, validation_accuracy = validation(model, validation_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()                                       # End time when one epoch will end executing\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)    # Calculate time consumed by one epoch (in minutes and seconds)\n",
        "      \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTraining Loss: {training_loss:.3f}   | Training Accuracy: {training_accuracy*100:.2f}%')\n",
        "    print(f'\\tValidation Loss: {validation_loss:.3f} |  Validation Accuracy: {validation_accuracy*100:.2f}%')\n",
        "\n",
        "print(\"\\n+=====================Execute the Testing Phase=====================+\\n\\n\")\n",
        "# Step 8: Execute the Testing Phase\n",
        "testing_loss, testing_accuracy = test(model, testing_iterator, criterion)\n",
        "print(f'Testing Loss: {testing_loss:.3f} | Testing Accuracy: {testing_accuracy*100:.2f}%')\n",
        "\n",
        "print(\"\\n+===================Execute the Application Phase===================+\\n\\n\")\n",
        "# Step 7: Execute the Application Phase\n",
        "\n",
        "user_input, seq_length = take_user_input(TEXT)   # Take unseen iput from user\n",
        "Gender = model_predictions(user_input, seq_length, drive_path)  # Make trained model predictions on user input\n",
        "print('\\033[1m',\"\\n\\nTrained Model Prediction\")\n",
        "print('\\033[1m',\"+\",\"=\"*30,\"+\")\n",
        "print('\\033[1m',\"|\",\" \"*30,\"|\\n           Gender : \", Gender,\"        \\n\",\"|                                |\")\n",
        "print('\\033[1m',\"+\",\"=\"*30,\"+\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "+=====================Execute the Training and Validation Phase=====================+\n",
            "\n",
            "\n",
            "Epoch: 01 | Epoch Time: 0m 1s\n",
            "\tTraining Loss: 0.723   | Training Accuracy: 50.00%\n",
            "\tValidation Loss: 0.723 |  Validation Accuracy: 50.00%\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTraining Loss: 0.723   | Training Accuracy: 50.00%\n",
            "\tValidation Loss: 0.723 |  Validation Accuracy: 50.00%\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTraining Loss: 0.723   | Training Accuracy: 50.00%\n",
            "\tValidation Loss: 0.723 |  Validation Accuracy: 50.00%\n",
            "Epoch: 04 | Epoch Time: 0m 1s\n",
            "\tTraining Loss: 0.723   | Training Accuracy: 50.00%\n",
            "\tValidation Loss: 0.723 |  Validation Accuracy: 50.00%\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTraining Loss: 0.723   | Training Accuracy: 50.00%\n",
            "\tValidation Loss: 0.723 |  Validation Accuracy: 50.00%\n",
            "Epoch: 06 | Epoch Time: 0m 1s\n",
            "\tTraining Loss: 0.723   | Training Accuracy: 50.00%\n",
            "\tValidation Loss: 0.723 |  Validation Accuracy: 50.00%\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTraining Loss: 0.723   | Training Accuracy: 50.00%\n",
            "\tValidation Loss: 0.723 |  Validation Accuracy: 50.00%\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTraining Loss: 0.723   | Training Accuracy: 50.00%\n",
            "\tValidation Loss: 0.723 |  Validation Accuracy: 50.00%\n",
            "Epoch: 09 | Epoch Time: 0m 1s\n",
            "\tTraining Loss: 0.723   | Training Accuracy: 50.00%\n",
            "\tValidation Loss: 0.723 |  Validation Accuracy: 50.00%\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTraining Loss: 0.723   | Training Accuracy: 50.00%\n",
            "\tValidation Loss: 0.723 |  Validation Accuracy: 50.00%\n",
            "\n",
            "+=====================Execute the Testing Phase=====================+\n",
            "\n",
            "\n",
            "Testing Loss: 0.723 | Testing Accuracy: 50.00%\n",
            "\n",
            "+===================Execute the Application Phase===================+\n",
            "\n",
            "\n",
            "Enter comment: If light is in your heart, you will find your way home\n",
            "\n",
            "Preprocessed User_input:\n",
            "==========================\n",
            "['<sos>', 'if', 'light', 'is', 'in', 'your', 'heart', 'you', 'will', 'find', 'your', 'way', 'home', '<eos>']\n",
            "\n",
            "Idx stored in vocab, corresponding to each word in user_input:\n",
            "==========================\n",
            "[2, 31, 166, 7, 12, 14, 30, 4, 40, 141, 14, 253, 0, 3]\n",
            "\n",
            "User_input as a tensor:\n",
            "==========================\n",
            "tensor([[  2],\n",
            "        [ 31],\n",
            "        [166],\n",
            "        [  7],\n",
            "        [ 12],\n",
            "        [ 14],\n",
            "        [ 30],\n",
            "        [  4],\n",
            "        [ 40],\n",
            "        [141],\n",
            "        [ 14],\n",
            "        [253],\n",
            "        [  0],\n",
            "        [  3]])\n",
            "\u001b[1m \n",
            "\n",
            "Trained Model Prediction\n",
            "\u001b[1m + ============================== +\n",
            "\u001b[1m |                                |\n",
            "           Gender :  Female         \n",
            " |                                |\n",
            "\u001b[1m + ============================== +\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuPnCVANis8r"
      },
      "source": [
        "# **Step 9: Execute the Feedback Phase**\n",
        "\n",
        "A Two Step Process\n",
        "*   Step 1: After sometime , take Feedback from \n",
        "  * Domain Experts and Users on deployed Gender Prediction System\n",
        "*   Step 2: Make a List of Possible Improvements based on Feedback received\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2S39PYA2JsD"
      },
      "source": [
        "# **Step 10: Improve Model based on Feedback**\n",
        "* There is Always Room for Improvement 😊\n",
        "* Based on Feedback form Domain Experts and Users\n",
        "  * Improve your Model \n"
      ]
    }
  ]
}